{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "import torch\n",
    "import torchinfo\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "from models import *\n",
    "from datasets import GunshotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "0.017445573583245277 : negative\n",
      "0.02835758402943611 : negative\n",
      "0.3268868029117584 : negative\n",
      "0.09615269303321838 : negative\n",
      "0.3005329668521881 : negative\n",
      "0.043674346059560776 : negative\n",
      "0.5081961154937744 : negative\n",
      "0.7469927668571472 : negative\n",
      "0.03297499194741249 : negative\n",
      "0.6285988688468933 : negative\n",
      "0.0794837698340416 : negative\n",
      "0.06883645057678223 : negative\n",
      "0.03200659155845642 : negative\n",
      "0.5939410924911499 : negative\n",
      "0.041939057409763336 : negative\n",
      "0.988934338092804 : negative\n",
      "0.04536587744951248 : negative\n",
      "0.021998178213834763 : negative\n",
      "0.0055379318073391914 : negative\n",
      "0.0031186279375106096 : negative\n",
      "0.0015643545193597674 : negative\n",
      "0.0012173077557235956 : negative\n",
      "0.0011251705000177026 : negative\n",
      "0.02721616066992283 : negative\n",
      "0.8690611720085144 : negative\n",
      "0.1265464723110199 : negative\n",
      "0.27860596776008606 : negative\n",
      "0.19945329427719116 : negative\n",
      "0.7288821339607239 : negative\n",
      "0.30214905738830566 : negative\n",
      "0.016690634191036224 : negative\n",
      "0.12767919898033142 : negative\n",
      "Interrupted.\n"
     ]
    }
   ],
   "source": [
    "# Producer parameters\n",
    "fs = 44100  # Sampling frequency\n",
    "chunk_duration = 2  # Chunk duration in seconds\n",
    "chunk_samples = int(fs * chunk_duration)  # Samples per chunk\n",
    "spec_dims = (256, 256)  # Spectrogram dimensions\n",
    "power = 2.0  # Power for spectrogram calculation\n",
    "\n",
    "# Queues for spectrograms and for plotting\n",
    "spec_queue = queue.Queue()\n",
    "# plot_queue = queue.Queue()\n",
    "inference_queue = queue.Queue()\n",
    "\n",
    "def make_spectrogram(waveform, n_samples, spec_dims, power):\n",
    "    n_ffts = (spec_dims[0] * 2) - 1\n",
    "    hop_length = max(1, int((n_samples - n_ffts) / (spec_dims[1] - 1)) + 2)\n",
    "    to_specgram = T.Spectrogram(n_fft=n_ffts, hop_length=hop_length, power=power)\n",
    "    power_to_dB = T.AmplitudeToDB(stype='power')\n",
    "    spec = to_specgram(waveform)\n",
    "    spec_dB = power_to_dB(spec)\n",
    "    return spec_dB\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    chunk = torch.tensor(indata[:, 0], dtype=torch.float32)\n",
    "    spec = make_spectrogram(chunk, chunk_samples, spec_dims, power)\n",
    "    spec_queue.put(spec.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "def record_audio():\n",
    "    with sd.InputStream(callback=audio_callback, channels=1, samplerate=fs, blocksize=chunk_samples):\n",
    "        print(\"Recording...\")\n",
    "        while True:\n",
    "            pass\n",
    "\n",
    "def monitor_queue():\n",
    "    \"\"\"Monitors the queue and prepares spectrograms for plotting.\"\"\"\n",
    "    try:\n",
    "        while True:\n",
    "            spectrogram = spec_queue.get()  # Blocks until an item is available\n",
    "            # plot_queue.put(spectrogram)\n",
    "            inference_queue.put(spectrogram)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped monitoring the queue.\")\n",
    "        \n",
    "def stream_and_infer():\n",
    "    # Load model\n",
    "    model = build_resnet18()\n",
    "    checkpoint = torch.load(\"checkpoints/resnet18.pth\")\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    try:\n",
    "        while True:\n",
    "            spec = inference_queue.get()\n",
    "            output = model(spec)\n",
    "            logit = F.sigmoid(output)\n",
    "            decision = \"positive\" if logit > 0.99 else \"negative\"\n",
    "            print(logit.item(), \":\", decision)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted.\")\n",
    "\n",
    "# def plot_spectrograms():\n",
    "#     \"\"\"Plot spectrograms from the plot queue on the main thread.\"\"\"\n",
    "#     try:\n",
    "#         while True:\n",
    "#             spectrogram = plot_queue.get()\n",
    "#             plt.figure(figsize=(10, 4))\n",
    "#             plt.imshow(spectrogram.numpy(), origin='lower')\n",
    "#             plt.colorbar(format='%+2.0f dB')\n",
    "#             plt.title('Spectrogram (dB)')\n",
    "#             plt.ylabel('Frequency Bin')\n",
    "#             plt.xlabel('Time Frame')\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "#     except KeyboardInterrupt:\n",
    "#         clear_output()\n",
    "#         print(\"Stopped plotting.\")\n",
    "\n",
    "\n",
    "# Start producer and consumer threads\n",
    "recording_thread = threading.Thread(target=record_audio)\n",
    "monitoring_thread = threading.Thread(target=monitor_queue)\n",
    "\n",
    "recording_thread.start()\n",
    "monitoring_thread.start()\n",
    "\n",
    "# Run the plotting function on the main thread\n",
    "stream_and_infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSDetector-SMtbqaNF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
